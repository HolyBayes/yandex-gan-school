{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as v_utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "mnist_transforms = transforms.Compose([ # Compose combines a number of transforms into one operation\n",
    "    transforms.ToTensor(), # PIL Image -> Tensor\n",
    "    transforms.Normalize([0.5], [0.5]) # input = (input - 0.5) / 0.5 -> x \\sim input \\in [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 3469524.51it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 210995.61it/s]           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1270337.57it/s]                             \n",
      "8192it [00:00, 82860.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# We can use torchvision package to get MNIST dataset\n",
    "\n",
    "data_path = \"../data/\"\n",
    "\n",
    "train_dataset = datasets.MNIST(data_path,\n",
    "                               train=True,\n",
    "                               transform=mnist_transforms,\n",
    "                               target_transform=None,\n",
    "                               download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(train_loader))\n",
    "print(f'Label: {label[0]}')\n",
    "plt.imshow(img[0, 0, :,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a GAN composed of two different modules, namely Generator and Discriminator. \n",
    "\n",
    "1. The Generator takes a noise from a latent space and outputs an image (1x28x28). The goal is to \"fool\" the Discriminator \n",
    "2. The Discriminator takes an image (1x28x28) and returns a probability of the image being real. The goal is to distinguish real images from generated ones.\n",
    "\n",
    "Using the binary cross enntropy loss we are minimizing the JS distance between the real and \"generated\" distribution, shifting \"generated\" images closer to the real ones. \n",
    "\n",
    "You can fing the original paper [here](https://www.arxiv-vanity.com/papers/1406.2661/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.upsample = nn.Upsample(\n",
    "            scale_factor=2,\n",
    "            mode='bilinear',\n",
    "            align_corners=True\n",
    "        )\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), # 16x7x7\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            self.upsample, # 16x14x14\n",
    "            nn.Conv2d(16, 32, 5, padding=2), # 32x14x14\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.LeakyReLU(),\n",
    "            self.upsample, # 32x28x28\n",
    "            nn.Conv2d(32, 32, 5, padding=2), # 32x28x28\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), # 32x28x28\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, 3, padding=1), # 1x28x28\n",
    "            nn.Tanh(), # 1x28x28 \\in [-1, 1]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 1, 7, 7)\n",
    "        x = self.layers(x)\n",
    "        return self.final_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 7, stride=2, padding=3), # 16x14x14\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 32, 5, stride=2, padding=2), # 32x7x7\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), # 32x7x7\n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 1, 3, padding=1), # 1x7x7\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.final_layers = nn.Sequential(\n",
    "            nn.Linear(1*7*7, 1)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.final_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 16, 7, 7]             160\n",
      "       BatchNorm2d-2             [-1, 16, 7, 7]              32\n",
      "         LeakyReLU-3             [-1, 16, 7, 7]               0\n",
      "          Upsample-4           [-1, 16, 14, 14]               0\n",
      "          Upsample-5           [-1, 16, 14, 14]               0\n",
      "            Conv2d-6           [-1, 32, 14, 14]          12,832\n",
      "       BatchNorm2d-7           [-1, 32, 14, 14]              64\n",
      "         LeakyReLU-8           [-1, 32, 14, 14]               0\n",
      "          Upsample-9           [-1, 32, 28, 28]               0\n",
      "         Upsample-10           [-1, 32, 28, 28]               0\n",
      "           Conv2d-11           [-1, 32, 28, 28]          25,632\n",
      "      BatchNorm2d-12           [-1, 32, 28, 28]              64\n",
      "        LeakyReLU-13           [-1, 32, 28, 28]               0\n",
      "           Conv2d-14           [-1, 32, 28, 28]           9,248\n",
      "      BatchNorm2d-15           [-1, 32, 28, 28]              64\n",
      "        LeakyReLU-16           [-1, 32, 28, 28]               0\n",
      "           Conv2d-17            [-1, 1, 28, 28]             289\n",
      "             Tanh-18            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 48,385\n",
      "Trainable params: 48,385\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.75\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 1.94\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "generator = Generator().to(device)\n",
    "print(summary(generator, (7*7, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 14, 14]             800\n",
      "       BatchNorm2d-2           [-1, 16, 14, 14]              32\n",
      "         LeakyReLU-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4             [-1, 32, 7, 7]          12,832\n",
      "       BatchNorm2d-5             [-1, 32, 7, 7]              64\n",
      "         LeakyReLU-6             [-1, 32, 7, 7]               0\n",
      "            Conv2d-7             [-1, 32, 7, 7]           9,248\n",
      "       BatchNorm2d-8             [-1, 32, 7, 7]              64\n",
      "         LeakyReLU-9             [-1, 32, 7, 7]               0\n",
      "           Conv2d-10              [-1, 1, 7, 7]             289\n",
      "        LeakyReLU-11              [-1, 1, 7, 7]               0\n",
      "           Linear-12                    [-1, 1]              50\n",
      "================================================================\n",
      "Total params: 23,379\n",
      "Trainable params: 23,379\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.14\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.24\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "print(summary(discriminator, (1, 28, 28)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/holybayes/yandex-school-gan-mnist/0b1c73e3175145a48770f61b2978a706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key=\"lODeHEtCf7XLaV6DJrOfugNcA\",\n",
    "                        project_name=\"yandex-school-gan-mnist\", workspace=\"holybayes\")\n",
    "\n",
    "LR = 0.001\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "def sample_noise(batch, dims, mean=0, std=0.1):\n",
    "    z = nn.init.normal_(torch.zeros(batch, dims, device=device), mean=mean, std=std)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd531c67de7943cea3dc7bab270e653a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch loop', max=10, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Train loop', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b907d72ece46028e3a80433caf7798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Train loop', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c43eff16ada6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoch loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miter_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/envs/tf_old/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_interval = 500\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc='Epoch loop'):\n",
    "    for iter_ind, (imgs, _) in tqdm(enumerate(train_loader), desc='Train loop', leave=False):\n",
    "        \n",
    "        ones = torch.ones(imgs.size(0), 1, device=device)\n",
    "        zeros = torch.zeros(imgs.size(0), 1, device=device)\n",
    "        step = epoch * len(train_loader) + iter_ind\n",
    "        \n",
    "        # generator update\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_imgs = generator(sample_noise(imgs.size(0), 7*7))\n",
    "        loss_G = criterion(discriminator(fake_imgs), ones)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # discriminator update\n",
    "        optimizer_D.zero_grad()\n",
    "        fake_imgs = generator(sample_noise(imgs.size(0), 7*7))\n",
    "        err_real = criterion(discriminator(imgs.to(device)), ones)\n",
    "        err_fake = criterion(discriminator(fake_imgs), zeros)\n",
    "        loss_D = err_real + err_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        experiment.log_metrics({'Generator loss': loss_G.item(),\n",
    "                                'Discriminator loss': loss_D.item()},\n",
    "                                epoch = epoch,\n",
    "                                step = step)        \n",
    "\n",
    "        if step % sample_interval == 0:\n",
    "            plt.figure(figsize = (10,10))\n",
    "\n",
    "            plt.title(\n",
    "                f\"[Epoch {epoch}/{n_epochs}]\" + \\\n",
    "                f\"[Batch {step%len(train_loader)}/{len(train_loader)}]\" + \\\n",
    "                f\"[D loss: {loss_D.item()}] [G loss: {loss_G.item()}]\"\n",
    "            )\n",
    "            \n",
    "            experiment.log_image(make_grid(fake_imgs.data[:25]).cpu().detach().numpy()[0, :, :])\n",
    "\n",
    "            plt.imshow(make_grid(fake_imgs.data[:25]).cpu().detach().numpy()[0, :, :])\n",
    "            experiment.log_figure()\n",
    "            plt.clf()\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *\n",
    "Some usefull [tricks](https://github.com/soumith/ganhacks/blob/master/README.md) for training GAN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
